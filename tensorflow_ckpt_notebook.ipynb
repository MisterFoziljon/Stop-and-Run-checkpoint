{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41be88-a382-4c7d-9261-ffc2a9ab62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d7bf1e-5e71-4202-ac34-f51e6e150ecf",
   "metadata": {},
   "source": [
    "#### Step 1: Loading dataset and preproccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01a1be9-43a9-4370-bb25-f9c329f5d24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 14:22:50.879427: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-21 14:22:50.914134: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-21 14:22:50.914757: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 14:22:51.708727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde88b1d-1a7d-4882-aeee-f1049b82463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "def one_hot_encoder(class_number,label_size):\n",
    "    label = np.zeros(label_size)\n",
    "    label[class_number] = 1\n",
    "    return label\n",
    "\n",
    "x_train = x_train.astype('float32')/255.0\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "\n",
    "x_train.reshape(x_train.shape[0],32,32,3)\n",
    "x_test.reshape(x_test.shape[0],32,32,3)\n",
    "\n",
    "y_train = np.array([one_hot_encoder(class_number,10) for class_number in y_train])\n",
    "y_test = np.array([one_hot_encoder(class_number,10) for class_number in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72cfac-882e-4a96-ae46-58d07a39ad9f",
   "metadata": {},
   "source": [
    "#### Step 2: Train Model, save checkpoints and stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54814d95-c0d9-468f-a52b-f9d67a2e185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843f0481-6e69-4d70-9cdf-f37a2c19f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'ckpt/checkpoint-{epoch:04d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "batch_size = 32\n",
    "n_batches = len(x_train) / batch_size\n",
    "n_batches = math.ceil(n_batches) \n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath = checkpoint_filepath,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=2*n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6393e5bf-f23a-44a8-a0a9-9b83e709cbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 16)        448       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                147520    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 14:22:58.991587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-21 14:22:58.991943: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173514 (677.79 KB)\n",
      "Trainable params: 173514 (677.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential([\n",
    "    Conv2D(16, kernel_size=(3, 3), activation=tf.keras.activations.relu, input_shape=(32,32,3)), # 30x30x16\n",
    "    Conv2D(32, kernel_size=(3, 3), activation=tf.keras.activations.relu), # 28x28x32\n",
    "    MaxPooling2D(pool_size=(2, 2)), # 14x14x32\n",
    "    Conv2D(64, (3, 3), activation=tf.keras.activations.relu), # 14x14x64\n",
    "    MaxPooling2D(pool_size=(2, 2)), # 7x7x64\n",
    "    Flatten(),\n",
    "    Dense(64, activation=tf.keras.activations.relu),\n",
    "    Dense(32, activation=tf.keras.activations.relu),\n",
    "    Dense(10, activation=tf.keras.activations.softmax)])\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.SGD(0.01), metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96761b3f-ef92-45b0-9995-409483339c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(checkpoint_filepath.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65504cdc-6925-4ad2-bce2-93a8da7ec8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 14:23:42.251281: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 29s 18ms/step - loss: 2.1341 - categorical_accuracy: 0.2096 - val_loss: 1.8625 - val_categorical_accuracy: 0.3211\n",
      "Epoch 2/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.6948 - categorical_accuracy: 0.3897\n",
      "Epoch 2: saving model to ckpt/checkpoint-0002.ckpt\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 1.6948 - categorical_accuracy: 0.3897 - val_loss: 1.5330 - val_categorical_accuracy: 0.4507\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 1.4521 - categorical_accuracy: 0.4762 - val_loss: 1.4238 - val_categorical_accuracy: 0.4937\n",
      "Epoch 4/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.3299 - categorical_accuracy: 0.5264\n",
      "Epoch 4: saving model to ckpt/checkpoint-0004.ckpt\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 1.3298 - categorical_accuracy: 0.5264 - val_loss: 1.3190 - val_categorical_accuracy: 0.5316\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 1.2286 - categorical_accuracy: 0.5657 - val_loss: 1.2088 - val_categorical_accuracy: 0.5671\n",
      "Epoch 6/20\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 1.1381 - categorical_accuracy: 0.5969\n",
      "Epoch 6: saving model to ckpt/checkpoint-0006.ckpt\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 1.1381 - categorical_accuracy: 0.5968 - val_loss: 1.2015 - val_categorical_accuracy: 0.5795\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 1.0608 - categorical_accuracy: 0.6284 - val_loss: 1.1601 - val_categorical_accuracy: 0.5980\n",
      "Epoch 8/20\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.9947 - categorical_accuracy: 0.6514\n",
      "Epoch 8: saving model to ckpt/checkpoint-0008.ckpt\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.9949 - categorical_accuracy: 0.6514 - val_loss: 1.0668 - val_categorical_accuracy: 0.6279\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.9363 - categorical_accuracy: 0.6712 - val_loss: 1.0629 - val_categorical_accuracy: 0.6328\n",
      "Epoch 10/20\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.8876 - categorical_accuracy: 0.6908\n",
      "Epoch 10: saving model to ckpt/checkpoint-0010.ckpt\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8880 - categorical_accuracy: 0.6906 - val_loss: 1.1153 - val_categorical_accuracy: 0.6205\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8405 - categorical_accuracy: 0.7068 - val_loss: 1.0075 - val_categorical_accuracy: 0.6492\n",
      "Epoch 12/20\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.7977 - categorical_accuracy: 0.7211\n",
      "Epoch 12: saving model to ckpt/checkpoint-0012.ckpt\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7979 - categorical_accuracy: 0.7211 - val_loss: 0.9627 - val_categorical_accuracy: 0.6683\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.7581 - categorical_accuracy: 0.7364 - val_loss: 0.9560 - val_categorical_accuracy: 0.6735\n",
      "Epoch 14/20\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.7199 - categorical_accuracy: 0.7500\n",
      "Epoch 14: saving model to ckpt/checkpoint-0014.ckpt\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.7198 - categorical_accuracy: 0.7500 - val_loss: 0.9440 - val_categorical_accuracy: 0.6839\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.6815 - categorical_accuracy: 0.7616 - val_loss: 0.9429 - val_categorical_accuracy: 0.6811\n",
      "Epoch 16/20\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6453 - categorical_accuracy: 0.7738\n",
      "Epoch 16: saving model to ckpt/checkpoint-0016.ckpt\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.6454 - categorical_accuracy: 0.7737 - val_loss: 0.9780 - val_categorical_accuracy: 0.6781\n",
      "Epoch 17/20\n",
      " 320/1563 [=====>........................] - ETA: 21s - loss: 0.5884 - categorical_accuracy: 0.7957"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9666/2557975052.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/checkpoint/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/checkpoint/env/lib/python3.10/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1729\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1733\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1734\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[1;32m   1735\u001b[0m                             \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m                             \u001b[0mepoch_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/checkpoint/env/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1397\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_step\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m         ):\n\u001b[1;32m   1399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m             \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m             can_run_full_execution = (\n\u001b[1;32m   1403\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/checkpoint/env/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    690\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;32m~/checkpoint/env/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/checkpoint/env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/checkpoint/env/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/checkpoint/env/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"graph\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;31m# Make sure we get an input with handle data attached from resource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_data\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/checkpoint/env/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   4095\u001b[0m         _ctx, \"Identity\", name, input)\n\u001b[1;32m   4096\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4097\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4098\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4099\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4100\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4102\u001b[0m       return identity_eager_fallback(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=20, validation_data=(x_test,y_test), callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b27151-9d55-4a54-ad21-745510aa661d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint-0014.ckpt.index',\n",
       " 'checkpoint-0006.ckpt.data-00000-of-00001',\n",
       " 'checkpoint',\n",
       " 'checkpoint-0010.ckpt.data-00000-of-00001',\n",
       " 'checkpoint-0000.ckpt.index',\n",
       " 'checkpoint-0000.ckpt.data-00000-of-00001',\n",
       " 'checkpoint-0016.ckpt.index',\n",
       " 'checkpoint-0004.ckpt.data-00000-of-00001',\n",
       " 'checkpoint-0012.ckpt.index',\n",
       " 'checkpoint-0008.ckpt.index',\n",
       " 'checkpoint-0010.ckpt.index',\n",
       " 'checkpoint-0006.ckpt.index',\n",
       " 'checkpoint-0012.ckpt.data-00000-of-00001',\n",
       " 'checkpoint-0016.ckpt.data-00000-of-00001',\n",
       " 'checkpoint-0002.ckpt.data-00000-of-00001',\n",
       " 'checkpoint-0004.ckpt.index',\n",
       " 'checkpoint-0014.ckpt.data-00000-of-00001',\n",
       " 'checkpoint-0002.ckpt.index',\n",
       " 'checkpoint-0008.ckpt.data-00000-of-00001']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594001e5-b3d3-4e96-a2d5-d185eda89fd8",
   "metadata": {},
   "source": [
    "#### Step 3: Loading last checkpoint, retrain model with last checkpoint and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f5c98db-501a-430e-9665-0de1fe0a832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4401474f-3533-4b81-abc4-6716ff6d785d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f1e730a24d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f18e24b4-2748-4194-8757-8aad53bd16d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   8/1563 [..............................] - ETA: 27s - loss: 0.5070 - categorical_accuracy: 0.8086"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 14:34:16.977205: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.6087 - categorical_accuracy: 0.7862 - val_loss: 1.0167 - val_categorical_accuracy: 0.6812\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.5736 - categorical_accuracy: 0.7985 - val_loss: 1.0057 - val_categorical_accuracy: 0.6744\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.5423 - categorical_accuracy: 0.8111 - val_loss: 0.9779 - val_categorical_accuracy: 0.6888\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.5100 - categorical_accuracy: 0.8210 - val_loss: 1.0033 - val_categorical_accuracy: 0.6916\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.4803 - categorical_accuracy: 0.8294 - val_loss: 1.0091 - val_categorical_accuracy: 0.6889\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.4483 - categorical_accuracy: 0.8420 - val_loss: 1.0318 - val_categorical_accuracy: 0.6858\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 29s 18ms/step - loss: 0.4178 - categorical_accuracy: 0.8518 - val_loss: 1.0879 - val_categorical_accuracy: 0.6839\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 27s 18ms/step - loss: 0.3889 - categorical_accuracy: 0.8634 - val_loss: 1.1700 - val_categorical_accuracy: 0.6718\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.3589 - categorical_accuracy: 0.8738 - val_loss: 1.1670 - val_categorical_accuracy: 0.6880\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.3317 - categorical_accuracy: 0.8834 - val_loss: 1.2570 - val_categorical_accuracy: 0.6798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1e730f4bb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=10, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaefe406-d7e4-4323-ad60-4babdd2d1c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrfoziljon/checkpoint/env/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
